{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM (horizontal TrainCut).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2PU8x7_l1T_k",
        "WSeNLjJQ1spj",
        "Q19byG_w3VYn",
        "WjCjFAOuX4Zd",
        "KgHgaQQHr0qm"
      ],
      "authorship_tag": "ABX9TyOz3sF4yDVppj9EocrBNrUk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/annsun123/historical-code/blob/main/LSTM_(horizontal_TrainCut).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xM2S5zhEmS9I"
      },
      "source": [
        "# Training Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYQrNXywYgTm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "b1cfe4a6-4fbc-47c1-d636-c328fc8557c7"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uf4mqKo01TH9"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Jun 11 13:31:44 2020\n",
        "@author: anyan.sun\n",
        "\n",
        "Steps:\n",
        "  First: decide length(Steps) of the Xs: taking 75 percentile of counts that happen in past [5,10,15,20,25,30] days \n",
        "  Second: Prepare X_train, y_train\n",
        "  Third: Train the Model and predict Output\n",
        "  Fourth: Compare the result\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "### Cutting Alternative I: \n",
        "# EEC, 1\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from itertools import combinations\n",
        "\n",
        "# there are 48, we are taing \n",
        "# which is i do have ac value which is greater than \n",
        "df_main=pd.read_excel('/content/drive/My Drive/Colab Notebooks/RR Folder/New_RR.xlsx') \n",
        "df_main['Date'] = df_main['Msg Time'].apply(lambda x: x.date())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pvxe9jhfugjG"
      },
      "source": [
        "## Decide length of X sequence\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5iNpBVOnBsM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 229
        },
        "outputId": "1c14a538-356d-40fe-88ae-aae2502657ba"
      },
      "source": [
        "df_RR = df_main[(df_main['Engine']==1) &(df_main['Source Type']=='EEC') \n",
        "        & (df_main['Side']==1.) & (df_main['FM'].notnull())]\n",
        "\n",
        "date_opt=[5,10,15,20,25,30]\n",
        "\n",
        "lenOpt_dic={}\n",
        "for date in date_opt:\n",
        "    len_opt = Get_Xlength(df_main, date, 'Date', duplicate='not_ignore')\n",
        "    try:\n",
        "        lenOpt_dic['date_rage: '+str(date)] = len_opt\n",
        "    except:\n",
        "        print('no value')\n",
        "\n",
        "## AC_opt = df_RR.groupby('AC')['Date'].count()[df_RR.groupby('AC')['Date'].count()>1000].keys()\n",
        "\n",
        "df_RR['FM'] = df_RR['FM'].astype('category')\n",
        "df_RR['fm_cat'] = df_RR['FM'].cat.codes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-d0b962a822d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlenOpt_dic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdate_opt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mlen_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGet_Xlength\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_main\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Date'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduplicate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'not_ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mlenOpt_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'date_rage: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen_opt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'Get_Xlength' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJIpKs6imfR2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "f2e1e7c1-3a86-4647-a154-d27ecebd137b"
      },
      "source": [
        "lenOpt_dic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'date_rage: 10': 17.0,\n",
              " 'date_rage: 15': 24.0,\n",
              " 'date_rage: 20': 29.0,\n",
              " 'date_rage: 25': 31.75,\n",
              " 'date_rage: 30': 39.0,\n",
              " 'date_rage: 5': 10.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqP0ay3J-PFq"
      },
      "source": [
        "cardinality = len(df_RR['fm_cat'].unique())\n",
        "seq_length = int(lenOpt_dic['date_rage: 15'])\n",
        "predict_gap = 5\n",
        "batch_size = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCsITGM22G-i"
      },
      "source": [
        "CatFM_dic={}\n",
        "FMCat_dic={}\n",
        "for ind, val in df_RR.drop_duplicates(['fm_cat','FM'])[['fm_cat','FM']].iterrows():\n",
        "  CatFM_dic[val['fm_cat']]=val['FM']\n",
        "  FMCat_dic[val['FM']]=val['fm_cat']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PU8x7_l1T_k"
      },
      "source": [
        "\n",
        "## Dropping the duplicated values "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZH8H42y6eR06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "665ef722-bb75-4486-db9a-64122f8c33b2"
      },
      "source": [
        "df=pd.DataFrame()\n",
        "for ac in df_RR['AC'].unique():\n",
        "    df_ac=df_RR[df_RR['AC']==ac].\\\n",
        "    sort_values(['Msg Time'])\n",
        "    \n",
        "    ##df_ac['class_1'] = df_ac['msg_text'].apply(lambda x: x.split('-')[0].strip())\n",
        "    #df_ac['engine_class'] = df_ac[['class_1', 'Source']].apply(lambda x: x['class_1']+ '_'+x['Source'],1)\n",
        "   # df1=df_check.drop_duplicates(['engine_class','FM']).groupby('engine_class')['FM'].count()\n",
        "    x=0\n",
        "    del_lst=[]\n",
        "    while x<len(df_ac)-1:    \n",
        "        if df_ac['Fault Code'].tolist()[x+1]==df_ac['Fault Code'].tolist()[x]:\n",
        "            del_lst.append(x)\n",
        "        x+=1\n",
        "       \n",
        "    df_ac=df_ac.drop(df_ac.index[del_lst]).reset_index(drop=True)\n",
        "    df=df.append(df_ac)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:40: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hrttbjRY1lBK"
      },
      "source": [
        "## Merging Small AC into \n",
        "\n",
        "remove the ac that is below certain number that is less than 25% \n",
        "  * merging the ac less 25%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8J1DMQnV55HZ"
      },
      "source": [
        "# minor_ac = np.percentile(df_RR.groupby('AC')['Date'].count(),25)\n",
        "minor_ac = seq_length+ (2*batch_size)\n",
        "AC_opt = df_RR.groupby('AC')['Date'].count()[df_RR.groupby('AC')['Date'].count()>=minor_ac].keys()\n",
        "AC_leftOut = df_RR.groupby('AC')['Date'].count()[df_RR.groupby('AC')['Date'].count()<minor_ac].keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6cLAbNa8JSo"
      },
      "source": [
        "df_normalAC=df_RR[df_RR['AC'].isin(AC_opt)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8Ui65Xd6Xxm"
      },
      "source": [
        "df_minor=pd.DataFrame()\n",
        "for ind, ac in enumerate(AC_leftOut):\n",
        "  df_ac=df_RR[df_RR['AC']==ac]\n",
        "  df_minor=df_minor.append(df_ac)\n",
        "\n",
        "df_minor['AC']='merge_'+str(ind)\n",
        "df_normalAC=df_normalAC.append(df_minor)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46Jih2276X1y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "outputId": "32523acb-0d1a-4853-d493-c130a91ba868"
      },
      "source": [
        "df_normalAC.groupby('AC')['Date'].count()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AC\n",
              "1           376\n",
              "2           382\n",
              "3           506\n",
              "4           383\n",
              "5           387\n",
              "6           408\n",
              "7           171\n",
              "8           486\n",
              "9           459\n",
              "10          501\n",
              "11          376\n",
              "12          111\n",
              "13          239\n",
              "14          164\n",
              "15          191\n",
              "16          244\n",
              "17          214\n",
              "18          106\n",
              "19          268\n",
              "21           38\n",
              "22          161\n",
              "23           80\n",
              "25           52\n",
              "34          104\n",
              "35          154\n",
              "36           82\n",
              "merge_10    110\n",
              "Name: Date, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSeNLjJQ1spj"
      },
      "source": [
        "## FIltering out Fault Code that is less than 5% \n",
        "** take fault count for every air craft, then remove fault count below 5% (consider the faults that only happen in nature)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8DjIDck1xb3"
      },
      "source": [
        "from collections import Counter\n",
        "df_final = pd.DataFrame()\n",
        "for ac in df_normalAC['AC'].unique():\n",
        "  df_ac = df_normalAC[df_normalAC['AC']==ac]\n",
        "  minor_value=np.percentile(list(Counter(df_ac['FM'].tolist()).values()),5)\n",
        "  fm_lst=df_ac.groupby('FM')['FM'].count()[df_ac.groupby('FM')['FM'].count()>minor_value].index.tolist()\n",
        "  df_ac=df_ac[df_ac['FM'].isin(fm_lst)]\n",
        "  df_final = df_final.append(df_ac)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52yEp_Us1xi6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "d34aa709-27c3-48c6-cd7c-0060f6143fa2"
      },
      "source": [
        "print(len(df_final))\n",
        "print(len(df_normalAC))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6667\n",
            "6753\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uh60Ir4oIgDK"
      },
      "source": [
        "score_log={}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zafS4_61xl2"
      },
      "source": [
        "## Test with last 20 %"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Z0I_okJADMa"
      },
      "source": [
        "### Validation Method I:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u81nDZ4YmP1E"
      },
      "source": [
        "def gen_80Test(df_RR, rolling_step, AC_opt, cardinality, seq_length, predict_gap, batch_size):\n",
        "  X_train=[]\n",
        "  y_train=[]\n",
        "  X_test=[]\n",
        "  y_test=[]\n",
        "\n",
        "  min_len = seq_length + predict_gap\n",
        "  df_train=pd.DataFrame(columns=df_RR['fm_cat'].unique())\n",
        "  for ac in AC_opt:\n",
        "      df_ac = df_RR[df_RR['AC']==ac].sort_values('Date')\n",
        "      ac_lst=df_ac['fm_cat'].tolist()[:int(len(df_ac)*0.8)]\n",
        "      sub_X, sub_y = generate_sequence(ac_lst, seq_length, predict_gap, rolling_step)\n",
        "      X_train.extend(sub_X)\n",
        "      y_train.extend(sub_y)\n",
        "     \n",
        "      \n",
        "      if len(ac_lst)*0.2 > min_len+seq_length:\n",
        "          test_lst=ac_lst[-int(len(ac_lst)*0.2):]\n",
        "      else: \n",
        "          test_lst=ac_lst[-(min_len+seq_length):]\n",
        "      sub_X, sub_y = generate_sequence(test_lst, seq_length, predict_gap, rolling_step)\n",
        "      X_test.extend(sub_X)\n",
        "      y_test.extend(sub_y)\n",
        "  X_train = to_categorical(X_train, num_classes=cardinality)\n",
        "  y_train = to_categorical(y_train, num_classes=cardinality)\n",
        "\n",
        "\n",
        "  X_test = to_categorical(X_test, num_classes=cardinality)\n",
        "  y_test = to_categorical(y_test, num_classes=cardinality)\n",
        "\n",
        "    \n",
        "  return X_train, y_train, X_test, y_test\n",
        "\n",
        "X_train, y_train, X_test, y_test = \\\n",
        "    gen_80Test(df_final,1, df_final['AC'].unique().tolist(),  cardinality, seq_length, predict_gap, batch_size)  \n",
        "\n",
        "X_train = X_train[len(X_train) % batch_size:]\n",
        "y_train = y_train[len(y_train) % batch_size:]\n",
        "X_test = X_test[len(X_test) % batch_size:]\n",
        "y_test = y_test[len(y_test) % batch_size:]\n",
        "\n",
        "#encoded_length = np.array(X_train).shape[2]\n",
        "#output = model_predict(seq_length, predict_gap, \n",
        " #             encoded_length,\n",
        "  #            batch_size, np.array(X_train),\n",
        "   #           np.array(y_train), np.array(X_test))\n",
        "\n",
        "#true_true, false_false = pred_score(output, y_test)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2yVwJB0Gi6x",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9c6939f-ffd5-4bcf-9437-7b96eb47b338"
      },
      "source": [
        "print(true_true, false_false)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9508771929824561 0.07894736842105263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3f81WpEIeKF"
      },
      "source": [
        "overall_8_2=[true_true, false_false]\n",
        "score_log['overall_8_2']=overall_8_2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpM0i0xeGfKd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "24454847-cc4b-4146-8043-f87ece2e8f81"
      },
      "source": [
        "acc_dic={}\n",
        "fakse_dic={}\n",
        "for ac in df_final['AC'].unique().tolist():\n",
        "\n",
        "  try:\n",
        "    X_train, y_train, X_test, y_test = \\\n",
        "      gen_80Test(df_final,1, [ac],  cardinality, seq_length, predict_gap, batch_size)\n",
        "\n",
        "\n",
        "    encoded_length = np.array(X_train).shape[2]\n",
        "    output = model_predict(seq_length, predict_gap, \n",
        "                  encoded_length,\n",
        "                  batch_size, np.array(X_train),\n",
        "                  np.array(y_train), np.array(X_test))\n",
        "    true_true, false_false = pred_score(output, y_test)\n",
        "    acc_dic[ac]=true_true\n",
        "    fakse_dic[ac]=false_false\n",
        "  except:\n",
        "    print('check array of ac_'+str(ac))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "check array of ac_25\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsyN1817SBKR"
      },
      "source": [
        "score_log"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNhJ7BW-R7TH"
      },
      "source": [
        "score_log['individual_ac']=[acc_dic,fakse_dic]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebrm8USz_-Kh"
      },
      "source": [
        "### Validation Method II: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ihd7Hry4_-R2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "224f13b2-720e-4518-b7df-89c805f13f08"
      },
      "source": [
        "encoded_length = np.array(X_train).shape[2]\n",
        "\n",
        "model = model_fit(seq_length, predict_gap, \n",
        "            encoded_length,\n",
        "            batch_size, np.array(X_train),\n",
        "            np.array(y_train))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O5LqgCwd0dmI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d34cb380-1911-4822-d211-9333f65c9bac"
      },
      "source": [
        "np.array(testX).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5, 24, 49)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbcC0j-wksaq"
      },
      "source": [
        "X_train = X_train[len(X_train) % batch_size:]\n",
        "y_train = y_train[len(y_train) % batch_size:]\n",
        "X_test = X_test[len(X_test) % batch_size:]\n",
        "y_test = y_test[len(y_test) % batch_size:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJ-cS6awg13f"
      },
      "source": [
        "validation_scr = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vtpLOHshhYl"
      },
      "source": [
        " X_train, y_train, X_test, y_test = \\\n",
        "      gen_80Test(df_final, 5, [ac], cardinality, seq_length, predict_gap, batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jbvlmVWnGV2E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "a6c65051-7fba-4e89-9c6b-5109ca0f527c"
      },
      "source": [
        "# actually is making rolling windows with 5 steps\n",
        "validationII_agg = []\n",
        "for roll_step in range(1,4,1):\n",
        "  validation_scr={}\n",
        "  validation_scr['ind_defi']=['length_of_y', 'true_true', 'false_false']\n",
        "  for ac in df_final['AC'].unique():\n",
        "\n",
        "    try:\n",
        "      X_train, y_train, X_test, y_test = \\\n",
        "            gen_80Test(df_final, roll_step, [ac], cardinality, seq_length, predict_gap, batch_size)\n",
        "      initial_test = X_test[0]\n",
        "      testX = [initial_test for n in range(5)]\n",
        "        \n",
        "      ac_score=[]\n",
        "      ac_FTscore=[]\n",
        "      \n",
        "    \n",
        "      for y in range(len(y_test)):\n",
        "        \n",
        "        y_true = [np.argmax(y_test[y][i]) for i in range(5)]\n",
        "        output = model.predict(np.array(testX))[0]\n",
        "      # for validation method 2, how many steps that we are going to loop over\n",
        "        pred_FM = []\n",
        "        for i in range(len(output)):\n",
        "          pred_FM.append(np.argmax(output[i]))\n",
        "        ac_score.append(len(set(pred_FM) & set(y_true))/len(set(y_true)))\n",
        "        ac_FTscore.append(1-(len(set(pred_FM) & set(y_true))/len(set(pred_FM))))\n",
        "        testArray = testX[0][roll_step:]\n",
        "        testX = np.append(testArray,output[:roll_step]).reshape(seq_length,cardinality)\n",
        "        testX=[testX for n in range(5)]\n",
        "      validation_scr['AC_'+str(ac)]=[len(y_test), np.sum(ac_score)/len(ac_score),np.sum(ac_FTscore)/len(ac_FTscore) ]\n",
        "   \n",
        "    except:\n",
        "      print('check length of df_ac')\n",
        "  validationII_agg.append(validation_scr)\n",
        " "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "check length of df_ac\n",
            "check length of df_ac\n",
            "check length of df_ac\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NW8ka-5noW3Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "outputId": "143c425b-558a-466c-a022-430aa21bea8a"
      },
      "source": [
        "validation_scr={}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'AC_1': [4, 0.5, 0.25],\n",
              " 'AC_10': [8, 1.0, 0.0],\n",
              " 'AC_11': [4, 0.5833333333333334, 0.25],\n",
              " 'AC_12': [3, 0.8333333333333334, 0.0],\n",
              " 'AC_13': [3, 0.0, 1.0],\n",
              " 'AC_14': [3, 1.0, 0.0],\n",
              " 'AC_15': [3, 0.6666666666666666, 0.0],\n",
              " 'AC_16': [3, 0.0, 1.0],\n",
              " 'AC_17': [3, 0.38888888888888884, 0.0],\n",
              " 'AC_18': [3, 0.8333333333333334, 0.16666666666666666],\n",
              " 'AC_19': [3, 0.16666666666666666, 0.6666666666666666],\n",
              " 'AC_2': [5, 1.0, 0.0],\n",
              " 'AC_22': [3, 0.16666666666666666, 0.6666666666666666],\n",
              " 'AC_23': [3, 0.8333333333333334, 0.0],\n",
              " 'AC_3': [8, 1.0, 0.0],\n",
              " 'AC_34': [3, 1.0, 0.0],\n",
              " 'AC_35': [3, 1.0, 0.0],\n",
              " 'AC_36': [3, 1.0, 0.0],\n",
              " 'AC_4': [5, 1.0, 0.0],\n",
              " 'AC_5': [5, 0.0, 1.0],\n",
              " 'AC_6': [5, 1.0, 0.0],\n",
              " 'AC_7': [3, 0.8333333333333334, 0.0],\n",
              " 'AC_8': [8, 0.9375, 0.0],\n",
              " 'AC_9': [7, 1.0, 0.0],\n",
              " 'AC_merge_10': [3, 0.38888888888888884, 0.16666666666666666],\n",
              " 'ind_defi': ['length_of_y', 'true_true', 'false_false']}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zw8Z1t7FrqUK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "16b51bab-9f40-424b-e8c5-c509705a6b50"
      },
      "source": [
        "# overall score\n",
        "for roll_step in range(len(validationII_agg)):\n",
        "  validation_scrSEE=validationII_agg[roll_step]\n",
        "  print('the overall scr for roll_step_' + str(roll_step) +\n",
        "        ' is '+str(np.sum([validation_scrSEE[key][1] for key in list(validation_scrSEE.keys())[1:]])/len(list(validation_scrSEE.keys())[1:])))\n",
        "  print(\"\"\"there are \"\"\" + \n",
        "        str(len([validation_scrSEE[key][1] for key in list(validation_scrSEE.keys())[1:] \\\n",
        "                 if validation_scrSEE[key][1]>0.75])) +\n",
        "  \"\"\" above 0.75 and there are total \"\"\" +\n",
        "   str(len(df_final['AC'].unique())) + ' which is ' +str(14/27))\n",
        " \n",
        "# print(np.sum(validation_scr[key][1])/len(list(validation_scr.keys())[1:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the overall scr for roll_step_0 is 0.6162913173782738\n",
            "there are 14 above 0.75 and there are total 27 which is 0.5185185185185185\n",
            "0.20346320346320346\n",
            "the overall scr for roll_step_1 is 0.6776537564999102\n",
            "there are 14 above 0.75 and there are total 27 which is 0.5185185185185185\n",
            "0.336431623931624\n",
            "the overall scr for roll_step_2 is 0.6519383394383395\n",
            "there are 14 above 0.75 and there are total 27 which is 0.5185185185185185\n",
            "0.27662037037037035\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDDFBAmD2VSr"
      },
      "source": [
        "print(np.sum([validation_scrSEE[key][1] for key in list(validation_scrSEE.keys())[1:] \\\n",
        "                 if validation_scrSEE[key][1]<0.75])/len([validation_scrSEE[key][1] for key in list(validation_scrSEE.keys())[1:] \\\n",
        "                 if validation_scrSEE[key][1]<0.75]))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uv-QeAl5tHtP"
      },
      "source": [
        "import json\n",
        "with open('validationIIAGG.json', 'w') as file:\n",
        "  json.dump(validationII_agg, file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8JFkcIDoueG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2c014660-56f0-4110-dd95-746747f0b9fc"
      },
      "source": [
        "X_train, y_train, X_test, y_test = \\\n",
        "          gen_80Test(df_final, 5, df_final['AC'].unique().tolist(), cardinality, seq_length, predict_gap, batch_size)\n",
        "initial_test = X_test[0]\n",
        "testX = [initial_test for n in range(5)]\n",
        "\n",
        "ac_score=[]\n",
        "\n",
        "\n",
        "for y in range(len(y_test)):\n",
        "  y_true = [np.argmax(y_test[y][i]) for i in range(5)]\n",
        "  output = model.predict(np.array(testX))[0]\n",
        "  pred_FM=[]\n",
        "# for validation method 2, how many steps that we are going to loop over\n",
        "  for i in range(len(output)):\n",
        "    pred_FM.append(np.argmax(output[i]))\n",
        "  ac_score.append(len(set(pred_FM) & set(y_true))/len(set(y_true)))\n",
        "\n",
        "  testArray = testX[0][5:]\n",
        "  testX = np.append(testArray,output).reshape(seq_length,cardinality)\n",
        "  testX=[testX for n in range(5)]\n",
        "#validation_scr[str(ac)+'scr_validationII']=\n",
        "print(np.sum(ac_score)/len(ac_score))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.09615384615384616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zs1OMpIsGlq-"
      },
      "source": [
        "validation_scr['overall_scr_validationII']=np.sum(overall_score)/len(overall_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVg5kstchJqo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4172e437-f8c3-437f-fa34-745d61cca926"
      },
      "source": [
        "validation_scr"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'overall_scr_validationII': 0.25833333333333336}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 181
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s8ZLCbXD4wS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "1b72c847-8c83-46f0-cb34-0241e739714c"
      },
      "source": [
        "testX=[initial_test for n in range(5)]\n",
        "output = model.predict(np.array([testArray_new for n in range(5)]))[0]\n",
        "for i in output:\n",
        "  print(np.argmax(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n",
            "40\n",
            "40\n",
            "40\n",
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksjt2dmPEMXQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "a4efceca-6220-4cad-bc4f-662f0c2a4c1c"
      },
      "source": [
        "for i in y_test[2]:\n",
        "  print(np.argmax(i))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40\n",
            "40\n",
            "40\n",
            "40\n",
            "40\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q19byG_w3VYn"
      },
      "source": [
        "## Test with last three months\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jv_qVpOHHjEf"
      },
      "source": [
        "# to split the data into those before 3 months and those after 3 months\n",
        "# so for example, there are mltiple ac, and there will be i "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qq4wwLEbO7OR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a8600440-220d-49f6-e987-f26ad2122121"
      },
      "source": [
        "acc3Month_dic={}\n",
        "false3Month_dic={}\n",
        "\n",
        "for ac in AC_opt:\n",
        "  try:\n",
        "    TrainSplit_Cut='vertical'\n",
        "    X_train, y_train, X_test, y_test = \\\n",
        "      gen_TrainTest(df_final, TrainSplit_Cut,'3_month',1, df_final['AC'].unique().tolist(),  cardinality, seq_length, predict_gap, batch_size)\n",
        "\n",
        "\n",
        "    encoded_length = np.array(X_train).shape[2]\n",
        "    output = model_predict(seq_length, predict_gap, \n",
        "                  encoded_length,\n",
        "                  batch_size, np.array(X_train),\n",
        "                  np.array(y_train), np.array(X_test))\n",
        "    true_true, false_false = pred_score(output, y_test)\n",
        "    acc3Month_dic[ac]=true_true\n",
        "    false3Month_dic[ac]=false_false\n",
        "\n",
        "  except:\n",
        "    print('check array of ac_'+str(ac))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "check array of ac_2\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "check array of ac_3\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "check array of ac_4\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n",
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTJr9woEEvDu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "70b02e18-d123-4d64-b570-97fb9c797ce9"
      },
      "source": [
        "acc3Month_dic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-2642dc1fd406>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0macc3Month_dic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'acc3Month_dic' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VI0X8hXZ6jd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5efb9e68-720a-46c0-b820-9fb6eabad213"
      },
      "source": [
        "true_true, false_false = pred_score(output, y_test)\n",
        "true_true"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8894736842105263"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjCjFAOuX4Zd"
      },
      "source": [
        "## Alternative I: testing with 3 rolling steps\n",
        "taking subset of last three month---doing the rolling window with more stpes (more than 1), like 3,4,5\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4bOdzVdYYGN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac31468-d38d-489e-95b5-0f65d76ee5a6"
      },
      "source": [
        "TrainSplit_Cut='vertical'\n",
        "X_train, y_train, X_test, y_test = \\\n",
        "    gen_TrainTest(df_final, TrainSplit_Cut, '20_per', 3, df_final['AC'].unique().tolist(),  cardinality, seq_length, predict_gap, batch_size)\n",
        "   \n",
        "\n",
        "encoded_length = np.array(X_train).shape[2]\n",
        "output = model_predict(seq_length, predict_gap, \n",
        "              encoded_length,\n",
        "              batch_size, np.array(X_train),\n",
        "              np.array(y_train), np.array(X_test))\n",
        "true_true, false_false = pred_score(output, y_test)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkuvjOcztwrJ"
      },
      "source": [
        "score_log['rolling_step_3']=[true_true, false_false]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNk826xqY0S0"
      },
      "source": [
        "with open ('score_log_new.json', 'w') as file:\n",
        "  json.dump(score_log,file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlbTEgRCd6My"
      },
      "source": [
        "# Predicting the Future \n",
        "\n",
        "\n",
        "and return one by one\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Step One: combine all the small AC as one\n",
        "\treport accuracy [80%, 20% ] # taking the last 20 out.\n",
        "take fault count for every air craft, then remove fault count below 5% (consider the faults that only happen in nature)\n",
        "---if found out total 60% records re-occurance, so the accuracy is always 60%. So only use some of the fault code. \n",
        " \tthen recreate the datasets\n",
        "\n",
        "Step Three: \n",
        "\n",
        "keep 25 sequence as it is, then next sequence for ac_1. The array will be 1000 (len of list 20, )\n",
        "1000, 25 each and 4 rows. For all the ac \n",
        "all these will be category. \n",
        "\n",
        "\n",
        "* how many length and features we are keeping. backfill or forwardfill with previous data\n",
        "\n",
        "\tstart with ac=1 and then create 5 rows. Then again come back\n",
        "\ttake flight phase_2 and take all aircraft then put into sequence of fault that happen\n",
        "\n",
        " \n",
        "\n",
        "\n",
        "train with different windows, and using that window and train with 100% and take last piece and predict the future coming result\n",
        "dynamic moving windows for different AC \n",
        "5 different Moving windows to test with AC and pickk up the best moving window which return best result.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGpWeuHJYYJV"
      },
      "source": [
        "ac_lst = df_RR[df_RR['AC']==2]['FM'].tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-Sa0Ry3UElf"
      },
      "source": [
        "## Predicting Next Coming Steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTI8aYb_Gv69"
      },
      "source": [
        "X_final=[]\n",
        "y_final=[]\n",
        "min_len = seq_length + (2*batch_size)\n",
        "\n",
        "for ac in AC_opt:#\n",
        "    df_ac = df_final[df_final['AC']==ac].sort_values('Date')\n",
        "    ac_lst=df_ac['fm_cat'].tolist()[:int(len(df_ac))]\n",
        "    sub_X, sub_y = generate_sequence(ac_lst, seq_length, predict_gap, 1)\n",
        "    X_final.extend(sub_X)\n",
        "    y_final.extend(sub_y)\n",
        "\n",
        "X_final = to_categorical(X_train, num_classes=cardinality)\n",
        "y_final = to_categorical(y_train, num_classes=cardinality)\n",
        "X_final = X_train[len(X_train) % batch_size:]\n",
        "y_final = y_train[len(y_train) % batch_size:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSXiTBvrxLF5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "189ed811-d63f-4039-9572-fe90e0b730ca"
      },
      "source": [
        "model = model_fit(seq_length, predict_gap, \n",
        "            encoded_length,\n",
        "            batch_size, np.array(X_final),\n",
        "            np.array(y_final))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJHMj3xIT_1F"
      },
      "source": [
        "### Last Step Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7U32nflfj5SN"
      },
      "source": [
        "min_len = seq_length + predict_gap\n",
        "ac = 3\n",
        "ac_lst = df_final[df_final['AC']==ac].sort_values('Date')['fm_cat'].tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSz3E2vJkU2T"
      },
      "source": [
        "### Doing Rolling windows for ten "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEJPnFHqj_xl"
      },
      "source": [
        "final_lst = ac_lst[-(10 + seq_length):]\n",
        "last_X = []\n",
        "for step in range(0, len(final_lst)-seq_length):\n",
        "  last_X.append(final_lst[step:step+seq_length])\n",
        " # final_lst.append(final_lst[step:step+seq_length])\n",
        "  \n",
        "final_array = to_categorical(last_X, num_classes=cardinality)\n",
        "encoded_length = np.array(final_array).shape[2]\n",
        "output=model.predict(final_array, batch_size=batch_size, verbose=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WgDHzgXHQwCF"
      },
      "source": [
        "final_output=[]\n",
        "for i in output:\n",
        "  pred_seq = []\n",
        "  for step in range(predict_gap):\n",
        "    pred_seq.append(CatFM_dic[np.argmax(i[step])])\n",
        "  final_output.append(pred_seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYZnIuA7jgKP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "00815b6c-4178-4288-db7f-0cc4a8924c8b"
      },
      "source": [
        "final_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[458.0, 458.0, 458.0, 458.0, 458.0],\n",
              " [460.0, 460.0, 460.0, 458.0, 458.0],\n",
              " [458.0, 458.0, 458.0, 458.0, 458.0],\n",
              " [223.0, 458.0, 458.0, 458.0, 458.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [458.0, 458.0, 458.0, 458.0, 458.0],\n",
              " [458.0, 458.0, 458.0, 458.0, 458.0],\n",
              " [458.0, 458.0, 458.0, 458.0, 458.0],\n",
              " [458.0, 458.0, 458.0, 458.0, 458.0],\n",
              " [458.0, 460.0, 460.0, 460.0, 460.0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VFa9pV64seZ9"
      },
      "source": [
        "### Last Step without Rolling Windows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXMCgUgHpCKm"
      },
      "source": [
        "# min_len = seq_length + predict_gap\n",
        "#for ac in [1,2,3]:\n",
        "last_X = []\n",
        "for ac in df_final['AC'].unique():\n",
        "  ac_lst = df_final[df_final['AC']==ac].sort_values('Date')['fm_cat'].tolist()\n",
        "\n",
        "  last_X.append(ac_lst[-seq_length:])\n",
        "  # final_lst.append(final_lst[step:step+seq_length])\n",
        "final_array = to_categorical(last_X, num_classes=cardinality)\n",
        "encoded_length = np.array(final_array).shape[2]\n",
        "output=model.predict(final_array, batch_size=batch_size, verbose=0)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dmDAjqTrpaS9"
      },
      "source": [
        "final_output=[]\n",
        "for i in output:\n",
        "  pred_seq = []\n",
        "  for step in range(predict_gap):\n",
        "    pred_seq.append(CatFM_dic[np.argmax(i[step])])\n",
        "  final_output.append(pred_seq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NI_Y5ZaipY6n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ac18b577-c84f-44a8-dd19-d41fdd4a4de2"
      },
      "source": [
        "final_output[2]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[458.0, 458.0, 458.0, 458.0, 458.0]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SfGNqrUGvpG"
      },
      "source": [
        "## Prediction with random choice\n",
        "\n",
        "[The performance is quiet nice]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7-WhMT-sUM2"
      },
      "source": [
        "random_sample = []\n",
        "random_output = []\n",
        "min_len = seq_length + predict_gap\n",
        "\n",
        "#for ac in df_final['AC'].unique().tolist():\n",
        "ac = 2\n",
        "ac_lst = df_final[df_final['AC']==ac].sort_values('Date')['fm_cat'].tolist()\n",
        "\n",
        "if len(ac_lst)*0.2 > 2*seq_length:\n",
        "    test_lst = ac_lst[-int(len(ac_lst)*0.2):]\n",
        "else: \n",
        "    test_lst = ac_lst[-(2*seq_length):]\n",
        "\n",
        "random_lst=[]\n",
        "\n",
        "for n in range(50):\n",
        "  sample = random.sample(test_lst,seq_length)\n",
        "  random_lst.append(sample)\n",
        "\n",
        "sample_array = to_categorical(random_lst, num_classes=cardinality)\n",
        "encoded_length = np.array(X_train).shape[2]\n",
        "output=model.predict(sample_array, batch_size=batch_size, verbose=0)\n",
        "\n",
        "for i in output:\n",
        "  pred_seq = []\n",
        "  for step in range(predict_gap):\n",
        "    pred_seq.append(CatFM_dic[np.argmax(i[step])])\n",
        "  random_output.append(pred_seq)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toIDq50p6ORx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ad814ab2-c7d9-473b-fe18-b39cfc0cb4dc"
      },
      "source": [
        "len(test_lst)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "75"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2NNsmQZ0spq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "4d1ad0f5-631e-419a-bc4a-f56ef2cfe6b8"
      },
      "source": [
        "random_output"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [461.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [326.0, 326.0, 326.0, 326.0, 326.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 459.0, 459.0, 459.0, 459.0],\n",
              " [459.0, 459.0, 461.0, 461.0, 461.0],\n",
              " [460.0, 459.0, 459.0, 459.0, 459.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [459.0, 459.0, 459.0, 459.0, 459.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [459.0, 459.0, 459.0, 459.0, 459.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 326.0, 326.0, 326.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [459.0, 459.0, 459.0, 459.0, 459.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 459.0, 459.0, 459.0, 459.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [459.0, 459.0, 459.0, 459.0, 459.0],\n",
              " [326.0, 326.0, 326.0, 326.0, 326.0],\n",
              " [459.0, 459.0, 459.0, 459.0, 459.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 458.0, 458.0, 458.0, 458.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [461.0, 461.0, 461.0, 461.0, 461.0],\n",
              " [459.0, 459.0, 459.0, 459.0, 459.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [326.0, 326.0, 326.0, 326.0, 326.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [460.0, 460.0, 460.0, 460.0, 460.0],\n",
              " [459.0, 459.0, 459.0, 459.0, 459.0]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-7Ibe1ysURe"
      },
      "source": [
        "ac_lst = df_final[df_final['AC']==ac].sort_values('Date')['fm_cat'].tolist()\n",
        "\n",
        "if len(ac_lst)*0.2 > 2*seq_length:\n",
        "    test_lst = ac_lst[-int(len(ac_lst)*0.2):]\n",
        "else: \n",
        "    test_lst = ac_lst[-(2*seq_length):]\n",
        "\n",
        "sample = random.sample(test_lst,seq_length)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgHgaQQHr0qm"
      },
      "source": [
        "### without process detail AC pred_Score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQrhym0BqXUy"
      },
      "source": [
        "with open ('/content/drive/My Drive/Colab Notebooks/RR Folder/score_log.json', ) as file:\n",
        "  score_log=json.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RVIVZsTRC5p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "outputId": "c1c1e077-0352-49f3-b966-ed63cec8e0e4"
      },
      "source": [
        "acc_dic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: 1.0,\n",
              " 2: 1.0,\n",
              " 3: 0.0,\n",
              " 4: 1.0,\n",
              " 5: 1.0,\n",
              " 6: 1.0,\n",
              " 7: 0.5333333333333333,\n",
              " 8: 1.0,\n",
              " 9: 1.0,\n",
              " 10: 1.0,\n",
              " 11: 0.0,\n",
              " 12: 1.0,\n",
              " 13: 0.9333333333333333,\n",
              " 14: 1.0,\n",
              " 15: 0.13333333333333333,\n",
              " 16: 1.0,\n",
              " 17: 0.8666666666666667,\n",
              " 18: 0.6666666666666666,\n",
              " 19: 0.26666666666666666,\n",
              " 22: 1.0,\n",
              " 34: 1.0,\n",
              " 35: 1.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz0FeuoErtsv"
      },
      "source": [
        "score_log['withoutProcess_AC_detail']=withoutProcess_AC_detail"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O238KRDYrxAY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b152351-2e4c-4eb8-bbdf-9f81d49c3fba"
      },
      "source": [
        "score_log"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'individual_ac': [{'1': 0.9333333333333333,\n",
              "   '10': 1.0,\n",
              "   '11': 0.0,\n",
              "   '12': 1.0,\n",
              "   '13': 1.0,\n",
              "   '14': 1.0,\n",
              "   '15': 1.0,\n",
              "   '16': 1.0,\n",
              "   '17': 1.0,\n",
              "   '18': 0.8,\n",
              "   '19': 1.0,\n",
              "   '2': 1.0,\n",
              "   '22': 0.8,\n",
              "   '23': 1.0,\n",
              "   '3': 0.0,\n",
              "   '34': 1.0,\n",
              "   '35': 1.0,\n",
              "   '36': 1.0,\n",
              "   '4': 1.0,\n",
              "   '5': 1.0,\n",
              "   '6': 1.0,\n",
              "   '7': 0.8,\n",
              "   '8': 1.0,\n",
              "   '9': 1.0,\n",
              "   'merge_11': 0.9333333333333333},\n",
              "  {'1': 0.2,\n",
              "   '10': 0.0,\n",
              "   '11': 1.0,\n",
              "   '12': 0.0,\n",
              "   '13': 0.0,\n",
              "   '14': 0.0,\n",
              "   '15': 0.0,\n",
              "   '16': 0.0,\n",
              "   '17': 0.0,\n",
              "   '18': 0.4,\n",
              "   '19': 0.06666666666666667,\n",
              "   '2': 0.0,\n",
              "   '22': 0.2,\n",
              "   '23': 0.0,\n",
              "   '3': 1.0,\n",
              "   '34': 0.0,\n",
              "   '35': 0.0,\n",
              "   '36': 0.0,\n",
              "   '4': 0.0,\n",
              "   '5': 0.0,\n",
              "   '6': 0.0,\n",
              "   '7': 0.2,\n",
              "   '8': 0.0,\n",
              "   '9': 0.0,\n",
              "   'merge_11': 0.13333333333333333}],\n",
              " 'overall_8_2': [0.9508771929824561, 0.07894736842105263],\n",
              " 'withoutProcess_AC_detail': {1: 1.0,\n",
              "  2: 1.0,\n",
              "  3: 0.0,\n",
              "  4: 1.0,\n",
              "  5: 1.0,\n",
              "  6: 1.0,\n",
              "  7: 0.5333333333333333,\n",
              "  8: 1.0,\n",
              "  9: 1.0,\n",
              "  10: 1.0,\n",
              "  11: 0.0,\n",
              "  12: 1.0,\n",
              "  13: 0.9333333333333333,\n",
              "  14: 1.0,\n",
              "  15: 0.13333333333333333,\n",
              "  16: 1.0,\n",
              "  17: 0.8666666666666667,\n",
              "  18: 0.6666666666666666,\n",
              "  19: 0.26666666666666666,\n",
              "  22: 1.0,\n",
              "  34: 1.0,\n",
              "  35: 1.0}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6Sro-cYmbfW"
      },
      "source": [
        "# Function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "as-qn_KYmYIM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "6a800e28-b799-4fba-ca6c-612d2242a82a"
      },
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"\n",
        "Created on Thu Jun 11 13:33:05 2020\n",
        "\n",
        "@author: anyan.sun\n",
        "\"\"\"\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "import random\n",
        "from itertools import combinations\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, RepeatVector, Dense, TimeDistributed\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "def filter_col(df, col_lst, val_lst):\n",
        "    '''\n",
        "    col_lst: [the col that need to be filtered]\n",
        "    val_lst: [the value of corresponding col to filter]\n",
        "    '''\n",
        "    \n",
        "    for (col,val) in zip(col_lst, val_lst):\n",
        "        df = df[df[col]==val]\n",
        "    return df\n",
        "\n",
        "# one hot encode sequence\n",
        "def one_hot_encode(sequence, n_unique):\n",
        "\tencoding = list()\n",
        "\tfor value in sequence:\n",
        "\t\tvector = [0 for _ in range(n_unique)]\n",
        "\t\tvector[value] = 1\n",
        "\t\tencoding.append(vector)\n",
        "\treturn array(encoding)\n",
        "\n",
        "# so encoded idea is similar as getting the 'FM' dummies \n",
        "    # encoded = pd.get_dummies('FM')\n",
        "\n",
        "# decode a one hot encoded string\n",
        "def one_hot_decode(encoded_seq):\n",
        "\treturn [argmax(vector) for vector in encoded_seq]\n",
        "\n",
        "\n",
        "# convert encoded sequence to supervised learning\n",
        "def to_supervised(encoded, n_in, n_out):\n",
        "\t# create lag copies of the sequence\n",
        "\tdf = DataFrame(encoded)\n",
        "\tdf = concat([df.shift(n_in-i-1) for i in range(n_in)], axis=1)\n",
        "\t# drop rows with missing values\n",
        "\tdf.dropna(inplace=True)\n",
        "\t# specify columns for input and output pairs\n",
        "\tvalues = df.values\n",
        "\twidth = encoded.shape[1]\n",
        "\tX = values.reshape(len(values), n_in, width)\n",
        "\ty = values[:, 0:(n_out*width)].reshape(len(values), n_out, width)\n",
        "\treturn X, y\n",
        "\n",
        "\n",
        "def df_resampling(df, date_col, fault_col, date_opt):\n",
        "  error_dummies=pd.get_dummies(df[fault_col])\n",
        "  error_dummies['datetime']=df[date_col].tolist()\n",
        "  error_dummies['datetime']=pd.to_datetime(error_dummies['datetime'])\n",
        "  error_dummies.index = error_dummies['datetime']\n",
        "  df_dummies=error_dummies.resample(date_opt).sum()\n",
        "  return df_dummies\n",
        "\n",
        "\n",
        "def Get_Xlength(df_RR, date_range, date_col, duplicate='not_ignore'):\n",
        "    '''\n",
        "    This function is used to calculate the length of Xs input\n",
        "        by studying about the all air carft\n",
        "    date: count num of faults with in the date range\n",
        "    duplicate: {ignore, not_ignore} \n",
        "        ignore: 460,460,460,459. all 460 counting as 1.\\\n",
        "                    so the total number of count is 2\n",
        "        not_ignore: 460,460,460,459. all 460 counting as individual fault.\\\n",
        "                so the total number of count is 4\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    fault_cnt=[0]\n",
        " \n",
        "    for ac in df_RR['AC'].unique():\n",
        "        \n",
        "        df_filt = df_RR[(df_RR['AC']==ac) & (df_RR['Source Type']=='EEC') \\\n",
        "                        & (df_RR['Side']==1.)].sort_values(by=date_col).reset_index(drop=True)\n",
        "        \n",
        "        if duplicate=='not_ignore':\n",
        "            df_filt1 = df_resampling(df_filt, 'Date', 'FM', str(date_range)+'D')\n",
        "        \n",
        "        else:\n",
        "            df_filt1 = df_resampling(df_filt, 'Date', 'FM', str(date_range)+'D')\n",
        "            df_filt1 = df_filt1.applymap(lambda x: False if x==0 else True)\n",
        "    \n",
        "        fault_cnt.extend([x for x in np.sum(df_filt1,1) if x!=0])\n",
        "        \n",
        "    fault_cnt.pop(0)\n",
        "    \n",
        "    return np.percentile(fault_cnt, 75)\n",
        "\n",
        "def model_predict(n_in, n_out, encoded_length,\\\n",
        "                  batch_size, srcTR_encoded, tarTR_encoded, srcTE_encoded):\n",
        "    # batch_size = len(X_train)\n",
        "\n",
        "    model = Sequential() \n",
        "    model.add(LSTM(150, batch_input_shape=(batch_size, n_in, encoded_length), stateful=True))\n",
        "    model.add(RepeatVector(n_out))\n",
        "    model.add(LSTM(150, return_sequences=True, stateful=True))\n",
        "    model.add(TimeDistributed(Dense(encoded_length, activation='softmax')))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "    model.fit(srcTR_encoded, tarTR_encoded, epochs=20, \\\n",
        "              batch_size=batch_size, verbose=5, shuffle=False)\n",
        "\n",
        "    output = model.predict(srcTE_encoded, batch_size=batch_size, verbose=0)\n",
        "    \n",
        "    return output\n",
        "\n",
        "def model_fit(n_in, n_out, encoded_length,\\\n",
        "                  batch_size, srcTR_encoded, tarTR_encoded):\n",
        "    # batch_size = len(X_train)\n",
        "\n",
        "    model = Sequential() \n",
        "    model.add(LSTM(150, batch_input_shape=(batch_size, n_in, encoded_length), stateful=True))\n",
        "    model.add(RepeatVector(n_out))\n",
        "    model.add(LSTM(150, return_sequences=True, stateful=True))\n",
        "    model.add(TimeDistributed(Dense(encoded_length, activation='softmax')))\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "    # optimizer= sgd/reul\n",
        "\n",
        "    model.fit(srcTR_encoded, tarTR_encoded, epochs=20, \\\n",
        "              batch_size=batch_size, verbose=5, shuffle=False)\n",
        "\n",
        "    return model\n",
        "    \n",
        "\n",
        "\n",
        "def generate_sequence(ac_lst, seq_length, predict_gap, rolling_step):  \n",
        "  X_lst=[]\n",
        "  y_lst=[]\n",
        "  #drop_num = len(ac_lst) % seq_length\n",
        "  #ac_lst_new = ac_lst[int(drop_num):]\n",
        "  num_elements = len(ac_lst)\n",
        "  for start in range(rolling_step, num_elements-seq_length-predict_gap-rolling_step, rolling_step):\n",
        "      stop=start+seq_length\n",
        "      X_lst.append(ac_lst[start:stop])\n",
        "      y_lst.append(ac_lst[stop:stop+predict_gap])\n",
        "  \n",
        "  return X_lst, y_lst\n",
        "\n",
        "## compare the predict result with the true values\n",
        "def pred_score(output, y_test):\n",
        "  detail_step=[]\n",
        "  y_check=[]\n",
        "  check_lst=[]\n",
        "  for case in range(len(output)):\n",
        "    indi_lst=[]\n",
        "    y_lst=[]\n",
        "    for step in range(predict_gap):\n",
        "      indi_lst.append(np.argmax(output[case][step]))\n",
        "      y_lst.append(np.argmax(y_test[case][step]))\n",
        "    \n",
        "    # print(case,step,np.argmax(tarTE_encoded[case][step]),np.argmax(output[case][step]))\n",
        "      detail_step.append(np.argmax(y_test[case][step])==np.argmax(output[case][step]))\n",
        "    # if able to predict more than one fualt type correctly without consider sequence\n",
        "    check_lst.append(indi_lst)\n",
        "    y_check.append(y_lst)\n",
        "\n",
        "  Ture_Ture=[]\n",
        "  False_True=[]\n",
        "  for ind in range(len(check_lst)):\n",
        "    # % fault predicted correctly among all faults happening in next 10 steps\n",
        "    Ture_Ture.append(len(set(y_check[ind]) & set(check_lst[ind]))/len(set(y_check[ind])))\n",
        "    # Fault that is predicted but not happening in the next 10 step\n",
        "    False_True.append(len([fault for fault in set(check_lst[ind]) if fault not in set(y_check[ind])])/10)\n",
        "    \n",
        "  return  np.sum([1 for score in Ture_Ture if score!=0])/len(Ture_Ture), \\\n",
        "    np.sum([1 for score in False_True if score!=0])/len(False_True)\n",
        "  \n",
        "'''\n",
        "  # train LSTM\n",
        "for epoch in range(20):\n",
        "\t# generate new random sequence\n",
        "\t\n",
        "\t# fit model for one epoch on this sequence\n",
        "\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\n",
        "\tmodel.reset_states()\n",
        "'''\n",
        "        \n",
        "#############################  \n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n  # train LSTM\\nfor epoch in range(20):\\n\\t# generate new random sequence\\n\\t\\n\\t# fit model for one epoch on this sequence\\n\\tmodel.fit(X, y, epochs=1, batch_size=batch_size, verbose=2, shuffle=False)\\n\\tmodel.reset_states()\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IEwN3zWYd-4l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "outputId": "ddf71083-b72e-4852-8dda-93ce0e07a34e"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import datetime\n",
        "from itertools import combinations\n",
        "import random\n",
        "\n",
        "\n",
        "ntrain=int(len(df_ac)*0.8)\n",
        "ntest=len(df_ac)-ntrain\n",
        "n = 15\n",
        "noffset=0\n",
        "nelements=ntrain\n",
        "sequence = ac_sequence\n",
        "###\n",
        "\n",
        "ncontext = n-3\n",
        "xs, ys = [], []\n",
        "noffset = max(0, noffset) # for debugging cases\n",
        "nelements = min(nelements, len(sequence)) # ditto\n",
        "\n",
        " \n",
        "\n",
        "for i in range(noffset, noffset + nelements - ncontext):\n",
        "      try:\n",
        "          x = sequence[i:i+ncontext]\n",
        "          y = sequence[i+ncontext:i+ncontext+3]\n",
        "          xs.append(x)\n",
        "          ys.append(y)\n",
        "      except:\n",
        "          continue;\n",
        "###\n",
        "\n",
        "#xs = np.array(xs).reshape(-1,12,1) #np.reshape(np.array(xs), (-1, 1, 1)) #np.array(xs)\n",
        "#ys = np.array(ys).reshape(-1,3,1) #np.reshape(np.array(ys), (-1, 1, 1)) #np.array(ys)\n",
        "\n",
        "###\n",
        "#xs_test = np.array(xs).reshape(-1,12,1) #\n",
        "xs_test=np.reshape(np.array(xs), (-1, 1, 12)) #np.array(xs)\n",
        " \n",
        "#ys_test = np.array(ys).reshape(-1,3,1) #np.reshape(np.array(ys), (-1, 1, 1)) #np.array(ys)\n",
        "\n",
        "###\n",
        "#xs_test = np.array(xs).reshape(-1,12,1) #\n",
        "array(xs)\n",
        " \n",
        "#ys_test = np.array(ys).reshape(-1,3,1) #np.reshape(np.array(ys), (-1, 1, 1)) #np.array(ys)\n",
        "ys_test = np.array(ys).reshape(-1,1,3)\n",
        "batch_size=12\n",
        "model = Sequential()\n",
        "model.add(LSTM(150, batch_input_shape=(batch_size,1,12), stateful=True))\n",
        "model.add(RepeatVector(1))\n",
        "model.add(LSTM(150, return_sequences=True, stateful=True))\n",
        "model.add(TimeDistributed(Dense(3, activation='relu')))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        " \n",
        "\n",
        "model.fit(xs_test, ys_test, epochs=20, \\\n",
        "             batch_size=12, verbose=5, shuffle=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "Epoch 2/20\n",
            "Epoch 3/20\n",
            "Epoch 4/20\n",
            "Epoch 5/20\n",
            "Epoch 6/20\n",
            "Epoch 7/20\n",
            "Epoch 8/20\n",
            "Epoch 9/20\n",
            "Epoch 10/20\n",
            "Epoch 11/20\n",
            "Epoch 12/20\n",
            "Epoch 13/20\n",
            "Epoch 14/20\n",
            "Epoch 15/20\n",
            "Epoch 16/20\n",
            "Epoch 17/20\n",
            "Epoch 18/20\n",
            "Epoch 19/20\n",
            "Epoch 20/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f3b71419b70>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMB4wsrSAJfl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8d3349a0-8a2b-462d-8c74-d6d59d8358ea"
      },
      "source": [
        "model.predict(xs_test,batch_size=12,verbose=5)\n",
        "#model.predict(np.array(testX))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[1.9338676 , 1.969222  , 1.9985031 ]],\n",
              "\n",
              "       [[1.9381351 , 2.08275   , 2.0833461 ]],\n",
              "\n",
              "       [[2.2186139 , 2.132873  , 2.195899  ]],\n",
              "\n",
              "       [[1.7870414 , 1.7115123 , 2.0189314 ]],\n",
              "\n",
              "       [[2.0384457 , 2.1963577 , 1.9387312 ]],\n",
              "\n",
              "       [[2.0441165 , 1.8100165 , 2.205     ]],\n",
              "\n",
              "       [[1.8566127 , 2.2309582 , 1.9936111 ]],\n",
              "\n",
              "       [[2.0953555 , 1.9280705 , 2.0076504 ]],\n",
              "\n",
              "       [[2.1329308 , 2.233043  , 2.141828  ]],\n",
              "\n",
              "       [[2.0635834 , 2.0056403 , 2.0733604 ]],\n",
              "\n",
              "       [[2.137746  , 2.0075898 , 2.0788574 ]],\n",
              "\n",
              "       [[2.0574508 , 1.912344  , 2.1379063 ]],\n",
              "\n",
              "       [[1.71677   , 1.7227801 , 2.179648  ]],\n",
              "\n",
              "       [[1.5953245 , 1.8550832 , 2.0379868 ]],\n",
              "\n",
              "       [[1.5595528 , 1.4842763 , 2.5743933 ]],\n",
              "\n",
              "       [[0.88195205, 2.1837997 , 1.3246647 ]],\n",
              "\n",
              "       [[1.8810399 , 1.7780892 , 1.737543  ]],\n",
              "\n",
              "       [[1.8486843 , 0.97372746, 2.7247925 ]],\n",
              "\n",
              "       [[1.0145885 , 2.295031  , 1.9872121 ]],\n",
              "\n",
              "       [[1.8379465 , 1.9145074 , 1.9184335 ]],\n",
              "\n",
              "       [[2.0248413 , 2.0782819 , 2.1688418 ]],\n",
              "\n",
              "       [[2.0475597 , 2.0351548 , 2.014333  ]],\n",
              "\n",
              "       [[2.2531123 , 2.0570097 , 2.0308282 ]],\n",
              "\n",
              "       [[2.0768104 , 2.0145051 , 1.9854535 ]],\n",
              "\n",
              "       [[1.8541608 , 1.8133368 , 1.98167   ]],\n",
              "\n",
              "       [[1.7138827 , 1.9971602 , 2.0264492 ]],\n",
              "\n",
              "       [[1.8550345 , 1.8774459 , 2.319621  ]],\n",
              "\n",
              "       [[1.4989638 , 1.8489323 , 1.6940958 ]],\n",
              "\n",
              "       [[2.0471342 , 1.9825118 , 1.7892491 ]],\n",
              "\n",
              "       [[1.9184968 , 1.512696  , 2.2318437 ]],\n",
              "\n",
              "       [[1.5603071 , 2.104497  , 1.9713567 ]],\n",
              "\n",
              "       [[2.0619626 , 1.9458011 , 1.9085307 ]],\n",
              "\n",
              "       [[1.9836719 , 2.1738033 , 2.1486049 ]],\n",
              "\n",
              "       [[2.0936904 , 2.057198  , 2.0820162 ]],\n",
              "\n",
              "       [[2.2117162 , 2.0808268 , 2.0897884 ]],\n",
              "\n",
              "       [[2.1281056 , 2.124394  , 2.1176176 ]],\n",
              "\n",
              "       [[1.8850676 , 1.8821135 , 1.9664983 ]],\n",
              "\n",
              "       [[1.8708332 , 2.0238693 , 2.0470133 ]],\n",
              "\n",
              "       [[2.040991  , 1.9329125 , 2.2549515 ]],\n",
              "\n",
              "       [[1.5549982 , 1.8995761 , 1.7903026 ]],\n",
              "\n",
              "       [[2.0511718 , 2.0607395 , 1.8489383 ]],\n",
              "\n",
              "       [[2.0048535 , 1.5885446 , 2.2519727 ]],\n",
              "\n",
              "       [[1.6835089 , 2.205193  , 1.9611019 ]],\n",
              "\n",
              "       [[2.1073067 , 1.9635068 , 1.893447  ]],\n",
              "\n",
              "       [[2.0064185 , 2.1751719 , 2.1481423 ]],\n",
              "\n",
              "       [[2.089893  , 2.0379746 , 2.0745876 ]],\n",
              "\n",
              "       [[2.194365  , 2.1007626 , 2.084991  ]],\n",
              "\n",
              "       [[2.1215248 , 2.151832  , 2.1503305 ]],\n",
              "\n",
              "       [[1.9057386 , 1.9201753 , 1.9594659 ]],\n",
              "\n",
              "       [[1.937705  , 2.0241084 , 2.0512528 ]],\n",
              "\n",
              "       [[2.1099367 , 2.0022545 , 2.1967192 ]],\n",
              "\n",
              "       [[1.5978053 , 1.8652393 , 1.8643361 ]],\n",
              "\n",
              "       [[2.0188212 , 2.1084332 , 1.8729945 ]],\n",
              "\n",
              "       [[2.0219233 , 1.6731753 , 2.2348514 ]],\n",
              "\n",
              "       [[1.7590551 , 2.2382746 , 1.9893526 ]],\n",
              "\n",
              "       [[2.1405818 , 1.9747553 , 1.8868831 ]],\n",
              "\n",
              "       [[2.0221155 , 2.189867  , 2.154666  ]],\n",
              "\n",
              "       [[2.0930705 , 2.029344  , 2.0689538 ]],\n",
              "\n",
              "       [[2.1841998 , 2.1135845 , 2.079472  ]],\n",
              "\n",
              "       [[2.1231694 , 2.173381  , 2.1774142 ]],\n",
              "\n",
              "       [[1.9154514 , 1.9508338 , 1.9550976 ]],\n",
              "\n",
              "       [[1.9877948 , 2.033089  , 2.0529118 ]],\n",
              "\n",
              "       [[2.1580863 , 2.0490923 , 2.162489  ]],\n",
              "\n",
              "       [[1.6250069 , 1.8426498 , 1.9193094 ]],\n",
              "\n",
              "       [[1.993892  , 2.1395566 , 1.8920318 ]],\n",
              "\n",
              "       [[2.0384338 , 1.7276099 , 2.2313108 ]],\n",
              "\n",
              "       [[1.8167536 , 2.2639651 , 2.0226555 ]],\n",
              "\n",
              "       [[2.1630607 , 1.982269  , 1.8822689 ]],\n",
              "\n",
              "       [[2.0332456 , 2.203628  , 2.1598964 ]],\n",
              "\n",
              "       [[2.0978794 , 2.025729  , 2.0649052 ]],\n",
              "\n",
              "       [[2.1820865 , 2.1235938 , 2.0737257 ]],\n",
              "\n",
              "       [[2.1261685 , 2.1900306 , 2.1974597 ]],\n",
              "\n",
              "       [[1.9201167 , 1.9724996 , 1.9520332 ]],\n",
              "\n",
              "       [[2.0248408 , 2.046174  , 2.0543623 ]],\n",
              "\n",
              "       [[2.190747  , 2.081277  , 2.1415348 ]],\n",
              "\n",
              "       [[1.6444275 , 1.8278806 , 1.9595491 ]],\n",
              "\n",
              "       [[1.9727874 , 2.1600246 , 1.9069349 ]],\n",
              "\n",
              "       [[2.0519955 , 1.7648683 , 2.2324247 ]],\n",
              "\n",
              "       [[1.8607063 , 2.2851293 , 2.049477  ]],\n",
              "\n",
              "       [[2.1786501 , 1.9869982 , 1.8786415 ]],\n",
              "\n",
              "       [[2.0414596 , 2.2153049 , 2.1646137 ]],\n",
              "\n",
              "       [[2.103024  , 2.0243611 , 2.0621324 ]],\n",
              "\n",
              "       [[2.1839333 , 2.1310596 , 2.0687242 ]],\n",
              "\n",
              "       [[2.129773  , 2.2021704 , 2.2128758 ]],\n",
              "\n",
              "       [[1.9217436 , 1.9876366 , 1.9498035 ]],\n",
              "\n",
              "       [[2.0524817 , 2.0595438 , 2.0560539 ]],\n",
              "\n",
              "       [[2.2135491 , 2.1039119 , 2.1283476 ]],\n",
              "\n",
              "       [[1.6587836 , 1.8180165 , 1.9894614 ]],\n",
              "\n",
              "       [[1.9555805 , 2.1726148 , 1.9187065 ]],\n",
              "\n",
              "       [[2.063174  , 1.7907286 , 2.2355342 ]],\n",
              "\n",
              "       [[1.8934841 , 2.3034525 , 2.0703819 ]],\n",
              "\n",
              "       [[2.189721  , 1.9899796 , 1.8755709 ]],\n",
              "\n",
              "       [[2.1366506 , 2.2499168 , 2.0498533 ]],\n",
              "\n",
              "       [[1.8472325 , 2.041051  , 2.0450573 ]],\n",
              "\n",
              "       [[1.9373633 , 1.9460104 , 1.9706496 ]],\n",
              "\n",
              "       [[2.0768278 , 2.0267868 , 2.1654546 ]],\n",
              "\n",
              "       [[1.8474259 , 2.0277739 , 1.9447287 ]],\n",
              "\n",
              "       [[1.9794209 , 1.9479265 , 1.9399204 ]],\n",
              "\n",
              "       [[2.1168125 , 1.9978313 , 2.085134  ]],\n",
              "\n",
              "       [[1.4668529 , 1.8594978 , 1.7853277 ]],\n",
              "\n",
              "       [[1.808337  , 2.0200782 , 1.9412256 ]],\n",
              "\n",
              "       [[1.7514881 , 1.4678342 , 2.501459  ]],\n",
              "\n",
              "       [[1.4166617 , 2.573995  , 1.6988541 ]],\n",
              "\n",
              "       [[2.395176  , 1.8459795 , 1.671235  ]],\n",
              "\n",
              "       [[2.0563054 , 2.253815  , 2.138228  ]],\n",
              "\n",
              "       [[2.0347946 , 2.074084  , 2.0665622 ]],\n",
              "\n",
              "       [[2.1063073 , 2.0471084 , 2.0102258 ]],\n",
              "\n",
              "       [[2.1392987 , 2.165969  , 2.1903477 ]],\n",
              "\n",
              "       [[1.8812435 , 1.9725392 , 1.9660379 ]],\n",
              "\n",
              "       [[2.04723   , 2.0664759 , 1.9694915 ]],\n",
              "\n",
              "       [[2.2199106 , 2.0682256 , 2.0706196 ]],\n",
              "\n",
              "       [[1.5600215 , 1.8681091 , 1.94275   ]],\n",
              "\n",
              "       [[1.848855  , 2.1649072 , 1.9492964 ]],\n",
              "\n",
              "       [[1.9283617 , 1.7265065 , 2.2577133 ]],\n",
              "\n",
              "       [[1.8048594 , 2.382213  , 1.9256364 ]],\n",
              "\n",
              "       [[2.2686694 , 1.9031128 , 1.8355153 ]],\n",
              "\n",
              "       [[2.0491252 , 2.2437778 , 2.1526384 ]],\n",
              "\n",
              "       [[2.0571902 , 2.0570471 , 2.0600832 ]],\n",
              "\n",
              "       [[2.1066206 , 2.080885  , 2.0325532 ]],\n",
              "\n",
              "       [[2.1486557 , 2.154965  , 2.1901102 ]],\n",
              "\n",
              "       [[1.8923827 , 1.9775848 , 1.9797623 ]],\n",
              "\n",
              "       [[2.0649185 , 2.0828907 , 1.9884664 ]],\n",
              "\n",
              "       [[2.232112  , 2.0962672 , 2.075378  ]],\n",
              "\n",
              "       [[1.583555  , 1.8563564 , 1.9761862 ]],\n",
              "\n",
              "       [[1.8468451 , 2.187913  , 1.9556437 ]],\n",
              "\n",
              "       [[1.9713936 , 1.7502884 , 2.211156  ]],\n",
              "\n",
              "       [[1.8510568 , 2.3529072 , 1.9976091 ]],\n",
              "\n",
              "       [[2.214777  , 1.9067047 , 1.8891585 ]],\n",
              "\n",
              "       [[2.0476456 , 2.2412386 , 2.1615963 ]],\n",
              "\n",
              "       [[2.073476  , 2.046452  , 2.0584064 ]],\n",
              "\n",
              "       [[2.106875  , 2.101069  , 2.0490184 ]],\n",
              "\n",
              "       [[2.1566334 , 2.149262  , 2.1940918 ]],\n",
              "\n",
              "       [[1.9024734 , 1.9844373 , 1.9884826 ]],\n",
              "\n",
              "       [[2.0762517 , 2.0952237 , 2.003936  ]],\n",
              "\n",
              "       [[2.2415056 , 2.1137037 , 2.0809565 ]],\n",
              "\n",
              "       [[1.6117502 , 1.8376597 , 2.006289  ]],\n",
              "\n",
              "       [[1.8501656 , 2.204184  , 1.9620947 ]],\n",
              "\n",
              "       [[2.00186   , 1.7688453 , 2.1757898 ]],\n",
              "\n",
              "       [[1.8881743 , 2.3436217 , 2.045883  ]],\n",
              "\n",
              "       [[2.1808028 , 1.910757  , 1.9283615 ]],\n",
              "\n",
              "       [[2.048832  , 2.242659  , 2.1668134 ]],\n",
              "\n",
              "       [[2.085504  , 2.0398085 , 2.0571046 ]],\n",
              "\n",
              "       [[2.1071978 , 2.1138563 , 2.0609646 ]],\n",
              "\n",
              "       [[2.1624146 , 2.145112  , 2.1971235 ]],\n",
              "\n",
              "       [[1.909691  , 1.9917414 , 1.9948019 ]],\n",
              "\n",
              "       [[2.0849342 , 2.106439  , 2.0150237 ]],\n",
              "\n",
              "       [[2.2497647 , 2.1276226 , 2.08595   ]],\n",
              "\n",
              "       [[1.6345868 , 1.8239636 , 2.0289836 ]],\n",
              "\n",
              "       [[1.853867  , 2.2150948 , 1.9672741 ]],\n",
              "\n",
              "       [[2.0224786 , 1.779176  , 2.1508803 ]],\n",
              "\n",
              "       [[1.9141417 , 2.3452873 , 2.0749514 ]],\n",
              "\n",
              "       [[2.1597118 , 1.9131675 , 1.9564189 ]],\n",
              "\n",
              "       [[2.0512404 , 2.2453294 , 2.170422  ]],\n",
              "\n",
              "       [[2.094607  , 2.0354028 , 2.0563297 ]],\n",
              "\n",
              "       [[2.1073167 , 2.1221128 , 2.0695724 ]],\n",
              "\n",
              "       [[2.166965  , 2.141902  , 2.1998925 ]],\n",
              "\n",
              "       [[1.915267  , 1.9982541 , 1.9995939 ]],\n",
              "\n",
              "       [[2.0918972 , 2.116081  , 2.0234027 ]],\n",
              "\n",
              "       [[2.2567587 , 2.1387386 , 2.0905943 ]],\n",
              "\n",
              "       [[1.6524341 , 1.8151284 , 2.0459285 ]],\n",
              "\n",
              "       [[1.8578339 , 2.222296  , 1.9713844 ]],\n",
              "\n",
              "       [[2.0359435 , 1.7848331 , 2.1330132 ]],\n",
              "\n",
              "       [[1.9330401 , 2.34968   , 2.0944872 ]],\n",
              "\n",
              "       [[2.146669  , 1.9140158 , 1.9768056 ]],\n",
              "\n",
              "       [[2.053844  , 2.2482328 , 2.1731944 ]],\n",
              "\n",
              "       [[2.1016479 , 2.0324194 , 2.0559442 ]],\n",
              "\n",
              "       [[2.1072786 , 2.12745   , 2.0758095 ]],\n",
              "\n",
              "       [[2.170539  , 2.1395016 , 2.2024426 ]],\n",
              "\n",
              "       [[1.9196128 , 2.003707  , 2.003256  ]],\n",
              "\n",
              "       [[2.097324  , 2.1241434 , 2.0299473 ]],\n",
              "\n",
              "       [[2.2625108 , 2.147656  , 2.0946703 ]],\n",
              "\n",
              "       [[1.6659765 , 1.8096232 , 2.058472  ]],\n",
              "\n",
              "       [[1.8614419 , 2.2271187 , 1.974482  ]],\n",
              "\n",
              "       [[2.0443878 , 1.7879481 , 2.119919  ]],\n",
              "\n",
              "       [[1.9468957 , 2.3545299 , 2.1082268 ]],\n",
              "\n",
              "       [[2.1387815 , 1.9138155 , 1.9918308 ]],\n",
              "\n",
              "       [[2.0560973 , 2.2509208 , 2.175396  ]],\n",
              "\n",
              "       [[2.1071577 , 2.0303645 , 2.0558043 ]],\n",
              "\n",
              "       [[2.1070619 , 2.130849  , 2.08032   ]],\n",
              "\n",
              "       [[2.1733565 , 2.1377947 , 2.2047558 ]],\n",
              "\n",
              "       [[1.923073  , 2.0080924 , 2.0060978 ]],\n",
              "\n",
              "       [[2.1014788 , 2.130738  , 2.0351887 ]],\n",
              "\n",
              "       [[2.2671378 , 2.1548169 , 2.098129  ]],\n",
              "\n",
              "       [[1.6761832 , 1.8062732 , 2.0678232 ]],\n",
              "\n",
              "       [[1.8646727 , 2.230369  , 1.9767464 ]],\n",
              "\n",
              "       [[2.049398  , 1.7897017 , 2.1101222 ]],\n",
              "\n",
              "       [[2.1079798 , 2.3951619 , 2.0035846 ]],\n",
              "\n",
              "       [[1.9164572 , 1.9853917 , 1.9668003 ]],\n",
              "\n",
              "       [[1.9079007 , 2.0964775 , 2.0215049 ]],\n",
              "\n",
              "       [[2.0198765 , 1.8818386 , 2.0214982 ]],\n",
              "\n",
              "       [[1.9997048 , 2.1373434 , 2.0988612 ]],\n",
              "\n",
              "       [[2.0433037 , 2.0155182 , 2.1102915 ]],\n",
              "\n",
              "       [[1.8393027 , 1.9026661 , 1.9474047 ]],\n",
              "\n",
              "       [[1.8726184 , 2.138408  , 1.8739711 ]],\n",
              "\n",
              "       [[2.1441536 , 1.9865763 , 2.193244  ]],\n",
              "\n",
              "       [[1.4155667 , 1.4877465 , 2.4092517 ]],\n",
              "\n",
              "       [[1.3499411 , 2.7311497 , 1.3194351 ]],\n",
              "\n",
              "       [[2.3942375 , 1.4639378 , 1.8849088 ]],\n",
              "\n",
              "       [[2.1190221 , 2.4276352 , 1.9735284 ]],\n",
              "\n",
              "       [[1.7807133 , 1.9993656 , 1.9814891 ]],\n",
              "\n",
              "       [[1.8996453 , 2.0019474 , 1.9268094 ]],\n",
              "\n",
              "       [[1.9810166 , 1.9012771 , 1.9781498 ]],\n",
              "\n",
              "       [[1.9218786 , 2.1045947 , 2.0767245 ]],\n",
              "\n",
              "       [[1.9585273 , 2.0005383 , 2.01434   ]],\n",
              "\n",
              "       [[1.793903  , 1.8573267 , 1.8719174 ]],\n",
              "\n",
              "       [[1.7198272 , 2.164205  , 1.7977363 ]],\n",
              "\n",
              "       [[2.0643563 , 1.9351655 , 2.20965   ]],\n",
              "\n",
              "       [[1.2564727 , 1.4108231 , 2.4235668 ]],\n",
              "\n",
              "       [[1.235822  , 2.7648673 , 1.1915454 ]],\n",
              "\n",
              "       [[2.5271807 , 1.3350279 , 1.8513898 ]],\n",
              "\n",
              "       [[1.9816794 , 2.4073453 , 2.060712  ]],\n",
              "\n",
              "       [[1.9443316 , 2.0107722 , 1.9887085 ]],\n",
              "\n",
              "       [[2.0568995 , 2.1081092 , 2.0180569 ]],\n",
              "\n",
              "       [[2.0678732 , 2.0256927 , 2.007666  ]],\n",
              "\n",
              "       [[1.9993379 , 2.0670333 , 2.1129942 ]],\n",
              "\n",
              "       [[2.0794113 , 2.0923324 , 2.0630808 ]],\n",
              "\n",
              "       [[1.8837686 , 1.8967453 , 1.9277812 ]],\n",
              "\n",
              "       [[1.8409164 , 2.1711173 , 1.946386  ]],\n",
              "\n",
              "       [[2.137957  , 2.0879788 , 2.1661022 ]],\n",
              "\n",
              "       [[1.4951727 , 1.6546676 , 2.1955976 ]],\n",
              "\n",
              "       [[1.7189834 , 2.3725896 , 1.6231889 ]],\n",
              "\n",
              "       [[2.2580492 , 1.5925598 , 1.994862  ]],\n",
              "\n",
              "       [[1.9692703 , 2.3846178 , 2.0841281 ]],\n",
              "\n",
              "       [[1.986644  , 1.9845867 , 1.983392  ]],\n",
              "\n",
              "       [[2.0728831 , 2.1553826 , 2.0537863 ]],\n",
              "\n",
              "       [[2.0711093 , 2.0055053 , 2.01719   ]],\n",
              "\n",
              "       [[2.0350344 , 2.0747223 , 2.125073  ]],\n",
              "\n",
              "       [[2.1039827 , 2.0977645 , 2.0951762 ]],\n",
              "\n",
              "       [[1.8916023 , 1.9237504 , 1.9405712 ]],\n",
              "\n",
              "       [[1.8497784 , 2.1572216 , 1.9763253 ]],\n",
              "\n",
              "       [[2.1489632 , 2.1046505 , 2.1567755 ]],\n",
              "\n",
              "       [[1.6039758 , 1.7145461 , 2.1566086 ]],\n",
              "\n",
              "       [[1.8181874 , 2.2841172 , 1.7484094 ]],\n",
              "\n",
              "       [[2.1556516 , 1.6757021 , 2.0425165 ]],\n",
              "\n",
              "       [[2.0113406 , 2.3593874 , 2.1129754 ]],\n",
              "\n",
              "       [[2.0289507 , 1.9665825 , 1.9849871 ]],\n",
              "\n",
              "       [[2.1301408 , 2.194281  , 2.098704  ]],\n",
              "\n",
              "       [[2.075657  , 1.9734719 , 2.013599  ]],\n",
              "\n",
              "       [[2.0616677 , 2.0841162 , 2.1347055 ]],\n",
              "\n",
              "       [[2.1525369 , 2.10682   , 2.1115208 ]],\n",
              "\n",
              "       [[1.8997824 , 1.9399782 , 1.9579474 ]],\n",
              "\n",
              "       [[1.913529  , 2.1174393 , 2.0314953 ]],\n",
              "\n",
              "       [[2.1950102 , 2.1120152 , 2.1988378 ]],\n",
              "\n",
              "       [[1.7204592 , 1.8347243 , 2.0726514 ]],\n",
              "\n",
              "       [[1.9206545 , 2.2108355 , 1.862521  ]],\n",
              "\n",
              "       [[2.006043  , 1.6667056 , 2.0698652 ]],\n",
              "\n",
              "       [[1.9173536 , 2.2726803 , 2.160289  ]],\n",
              "\n",
              "       [[1.9631214 , 1.9661257 , 1.8992481 ]],\n",
              "\n",
              "       [[2.133149  , 2.2138505 , 2.0250823 ]],\n",
              "\n",
              "       [[2.174142  , 1.9942886 , 2.0924075 ]],\n",
              "\n",
              "       [[2.1269968 , 2.0715375 , 2.164602  ]],\n",
              "\n",
              "       [[2.1467931 , 2.105668  , 2.1053057 ]],\n",
              "\n",
              "       [[1.9010086 , 1.9664063 , 1.9161544 ]],\n",
              "\n",
              "       [[1.9608158 , 2.094454  , 2.0608518 ]],\n",
              "\n",
              "       [[2.2147117 , 2.1505876 , 2.132498  ]],\n",
              "\n",
              "       [[1.8038026 , 1.8146861 , 2.0701547 ]],\n",
              "\n",
              "       [[1.9958587 , 2.1727223 , 1.8334565 ]],\n",
              "\n",
              "       [[2.0652194 , 1.7429028 , 2.0802464 ]],\n",
              "\n",
              "       [[1.9190235 , 2.318196  , 2.0959163 ]],\n",
              "\n",
              "       [[2.0109606 , 1.9597639 , 1.8822445 ]],\n",
              "\n",
              "       [[2.15858   , 2.1957912 , 2.070481  ]],\n",
              "\n",
              "       [[2.1780312 , 2.030946  , 2.034054  ]],\n",
              "\n",
              "       [[2.1088629 , 2.1203494 , 2.1612039 ]],\n",
              "\n",
              "       [[2.2184587 , 2.1389909 , 2.077978  ]],\n",
              "\n",
              "       [[1.9275978 , 1.9552293 , 1.9280843 ]],\n",
              "\n",
              "       [[1.9930284 , 2.0773294 , 2.079264  ]],\n",
              "\n",
              "       [[2.2188404 , 2.1401339 , 2.185192  ]],\n",
              "\n",
              "       [[1.8081766 , 1.7881224 , 1.9992037 ]],\n",
              "\n",
              "       [[2.0163648 , 2.181615  , 1.8661538 ]],\n",
              "\n",
              "       [[2.099708  , 1.8141873 , 2.1016495 ]],\n",
              "\n",
              "       [[1.960141  , 2.350772  , 2.1205344 ]],\n",
              "\n",
              "       [[2.0653625 , 1.9610517 , 1.9271358 ]],\n",
              "\n",
              "       [[2.1443505 , 2.2306814 , 2.0814075 ]],\n",
              "\n",
              "       [[2.1391606 , 2.007738  , 2.0496004 ]],\n",
              "\n",
              "       [[2.0997462 , 2.1085162 , 2.173347  ]],\n",
              "\n",
              "       [[2.179131  , 2.1302288 , 2.1546462 ]],\n",
              "\n",
              "       [[1.9360425 , 1.9675596 , 1.9530786 ]],\n",
              "\n",
              "       [[1.955599  , 2.09916   , 2.051227  ]],\n",
              "\n",
              "       [[2.2148767 , 2.1445408 , 2.1698356 ]],\n",
              "\n",
              "       [[1.8433697 , 1.8354349 , 2.0409493 ]],\n",
              "\n",
              "       [[2.0313373 , 2.2005236 , 1.8916785 ]],\n",
              "\n",
              "       [[2.0602903 , 1.8162512 , 2.1480246 ]],\n",
              "\n",
              "       [[1.9627353 , 2.3598337 , 2.1253061 ]],\n",
              "\n",
              "       [[2.0837646 , 1.949276  , 1.9539696 ]],\n",
              "\n",
              "       [[2.1391644 , 2.238577  , 2.0969656 ]],\n",
              "\n",
              "       [[2.123887  , 1.9996252 , 2.0527666 ]],\n",
              "\n",
              "       [[2.1049168 , 2.1119092 , 2.1703022 ]],\n",
              "\n",
              "       [[2.1751869 , 2.1288924 , 2.167882  ]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33JyDsyNfYEh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "outputId": "c16adb35-d86f-49ea-f86b-c6d857c025aa"
      },
      "source": [
        "model = Sequential() \n",
        "model.add(LSTM(150, batch_input_shape=(12, 12, 1), stateful=True))\n",
        "model.add(RepeatVector(3))\n",
        "model.add(LSTM(150, return_sequences=True, stateful=True))\n",
        "model.add(TimeDistributed(Dense(1, activation='softmax')))\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        " \n",
        "\n",
        "model.fit(xs, ys, epochs=20, \\\n",
        "             batch_size=12, verbose=5, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-94-bb30d7e0cbbd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m              \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3790\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3791\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3792\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3794\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1603\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m     \"\"\"\n\u001b[0;32m-> 1605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1607\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1643\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1644\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1645\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  Received a label value of 460 which is outside the valid range of [0, 1).  Label values: 460 460 460 460 460 460 460 460 460 460 460 460 460 460 460 460 460 460 460 460 39 460 39 39 39 39 39 39 39 39 39 39 39 39 39 39\n\t [[node loss_18/time_distributed_17_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits (defined at /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3009) ]] [Op:__inference_keras_scratch_graph_45428]\n\nFunction call stack:\nkeras_scratch_graph\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RMsBlFCPE0jS"
      },
      "source": [
        "def gen_TrainTest(df_RR, TrainSplit_Cut, verti_cutMeth, rolling_step, AC_opt, cardinality,\\\n",
        "                  seq_length, predict_gap, batch_size):\n",
        "    '''\n",
        "    TrainSplit_Cut=='horizontal':\n",
        "       Stacking 80% of length of each AC and taking all AC\n",
        "    \n",
        "    TrainSplit_Cut=='vertical':\n",
        "       Stacking 80% AC but testing over another 20% AC \n",
        "       \n",
        "    \n",
        "    '''\n",
        "\n",
        "    X_train=[]\n",
        "    y_train=[]\n",
        "    X_test=[]\n",
        "    y_test=[]\n",
        "    if TrainSplit_Cut=='horizontal':\n",
        "        #for train, test in zip(train_ac[:5], test_ac[:5]):\n",
        "        #train_ac should be list of ac to train, test_ac should be list of ac for testing\n",
        "       \n",
        "      train_ac = AC_opt[0:int(len(AC_opt)*0.8)]\n",
        "      test_ac = AC_opt[int(len(AC_opt)*0.8):]\n",
        "    \n",
        "      df_Train = df_RR[df_RR['AC'].isin(train_ac)]\n",
        "      df_Test = df_RR[df_RR['AC'].isin(test_ac)]\n",
        "      \n",
        "\n",
        "      for ac in df_Train['AC'].unique():\n",
        "          ac_lst = df_Train[df_Train['AC']==ac].sort_values(['Date'])['fm_cat'].tolist()\n",
        "          sub_X, sub_y = generate_sequence(ac_lst, seq_length, predict_gap, rolling_step)\n",
        "          X_train.extend(sub_X)\n",
        "          y_train.extend(sub_y)\n",
        "          \n",
        "      \n",
        "\n",
        "      for ac in df_Test['AC'].unique():\n",
        "        ac_lst = df_Test[df_Test['AC']==ac].sort_values('Date')['fm_cat'].tolist()\n",
        "        sub_X, sub_y = generate_sequence(ac_lst, seq_length, predict_gap, rolling_step)\n",
        "        X_test.extend(sub_X)\n",
        "        y_test.extend(sub_y)\n",
        "        \n",
        "      X_train = to_categorical(X_train, num_classes=cardinality)\n",
        "      y_train = to_categorical(y_train, num_classes=cardinality)\n",
        "      X_train = X_train[len(X_train) % batch_size:]\n",
        "      y_train = y_train[len(y_train) % batch_size:]\n",
        "  \n",
        "      X_test = to_categorical(X_test, num_classes=cardinality)\n",
        "      y_test = to_categorical(y_test, num_classes=cardinality)\n",
        "      X_test = X_test[len(X_test) % batch_size:]\n",
        "      y_test = y_test[len(y_test) % batch_size:]\n",
        "      \n",
        "\n",
        "    elif TrainSplit_Cut=='vertical': \n",
        "      min_len = seq_length + batch_size\n",
        "      df_train=pd.DataFrame(columns=df_RR['fm_cat'].unique())\n",
        "      for ac in AC_opt:\n",
        "          df_ac = df_RR[df_RR['AC']==ac].sort_values('Date')\n",
        "          ac_lst=df_ac['fm_cat'].tolist()\n",
        "          sub_X, sub_y = generate_sequence(ac_lst, seq_length, predict_gap, rolling_step)\n",
        "          X_train.extend(sub_X)\n",
        "          y_train.extend(sub_y)\n",
        "          if verti_cutMeth=='20_per':\n",
        "           \n",
        "            if len(ac_lst)*0.2 > min_len+seq_length:\n",
        "                test_lst=ac_lst[-int(len(ac_lst)*0.2):]\n",
        "            else: \n",
        "                test_lst=ac_lst[-(min_len+seq_length):]\n",
        "            sub_X, sub_y = generate_sequence(test_lst, seq_length, predict_gap, rolling_step)\n",
        "            X_test.extend(sub_X)\n",
        "            y_test.extend(sub_y)\n",
        "\n",
        "          elif verti_cutMeth=='3_month':\n",
        "            x=3\n",
        "            while x<10:\n",
        "              test_lst = df_ac[df_ac['Date']>datetime.date(df_ac['Date'].max().year, df_ac['Date'].max().month-x, df_ac['Date'].max().day)]['fm_cat'].tolist()\n",
        "              if len(ac_lst)<min_len+seq_length:\n",
        "                x=x+1\n",
        "\n",
        "              else:\n",
        "                x=11\n",
        "\n",
        "            if len(ac_lst)==min_len+seq_length:\n",
        "              test_lst=ac_lst\n",
        "            else:\n",
        "              test_lst=ac_lst[-(min_len+seq_length):]\n",
        "\n",
        "            sub_X, sub_y = generate_sequence(test_lst, seq_length, predict_gap, rolling_step)\n",
        "            X_test.extend(sub_X)\n",
        "            y_test.extend(sub_y)\n",
        "            \n",
        "      X_train = to_categorical(X_train, num_classes=cardinality)\n",
        "      y_train = to_categorical(y_train, num_classes=cardinality)\n",
        "      X_train = X_train[len(X_train) % batch_size:]\n",
        "      y_train = y_train[len(y_train) % batch_size:]\n",
        "  \n",
        "      X_test = to_categorical(X_test, num_classes=cardinality)\n",
        "      y_test = to_categorical(y_test, num_classes=cardinality)\n",
        "      X_test = X_test[len(X_test) % batch_size:]\n",
        "      y_test = y_test[len(y_test) % batch_size:]\n",
        "        \n",
        "    return X_train, y_train, X_test, y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PpYYzZKKEOL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWPEHLTNKESI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9IvAGmgDKEWI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5kGKHIfvKEZc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG9TfrC4KEcQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}